<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Blog Posts - E. Mehmet Kıral</title>

    <!-- MathJax -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <link rel="stylesheet" href="math-blog.css" />

    <!-- This loads Google's tracking library -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3Q7M9XHEG5"></script>

<!-- This initializes tracking on your page -->
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-3Q7M9XHEG5');  // Your unique ID goes here
</script>
    
</head>
<body>
    <h1>Mathematical Vignettes</h1>
    
    <p>
    Below are short expositions of machine learning topics, with 
    a mathematical focus. The posts are not meant to be a first 
    introduction to the topic (except perhaps for a mathematician), 
    but rather exhibit the way I think about these topics and what 
    I personally focus on.
</p>

    <div class="nav-home">
        <a href="../index.html">← Back to Homepage</a>
    </div>


    <div class="post-preview">
        <input type="checkbox" id="post1" class="toggle">
        <label for="post1" class="post-title">
            <span class="expand-icon">+</span>
            But what is a gradient?
        </label>
        <div class="post-meta">2025/08/01</div>
        <div class="post-summary">
            <p>The differential of a loss function <span class="math inline">\(\,\mathrm{d}\ell(\mathbf{\boldsymbol{\theta}})\)</span>
    is a row vector, and the gradient <span class="math inline">\(\nabla\ell(\mathbf{\boldsymbol{\theta}})\)</span>
    is its transpose, a column vector. But what does this all mean?...
            <a href="2025-08-01_what-is-gradient.html" class="read-more">Read full post →</a>
            </p>
            
        </div>
    </div>

    <div class="post-preview">
        <input type="checkbox" id="post2" class="toggle">
        <label for="post2" class="post-title">
            <span class="expand-icon">+</span>
            Steepest descent needs geometry
        </label>
        <div class="post-meta">2025/06/15</div>
        <div class="post-summary">
            <p>The oft repeated mantra goes as follows; “<em>Gradient descent
    takes a step in the direction of steepest descent,</em>” with which
    nothing is wrong, but needs to be put under the microscope.</p><p>For a loss function <span class="math inline">\(\ell : \Theta \to
    \mathbb{R}\)</span>, and a step size <span class="math inline">\(\alpha &gt; 0\)</span>, the update algorithm
    is <span class="math display">\[\label{eq:gradient_descent}
        \mathbf{\boldsymbol{\theta}} \leftarrow
    \mathbf{\boldsymbol{\theta}} - \alpha \nabla
    \ell(\mathbf{\boldsymbol{\theta}}).\]</span> The intuitive picture
    is that we stand on a hilly landscape during an thick morning fog
    and want to go downhill. We can only sense the immediate steepness
    and take a step downhill along the negative gradient direction....
            <a href="2025-06-15_gradient-descent.html" class="read-more">Read full post →</a>
            </p>
            
        </div>
    </div>

    <div class="post-preview">
        <input type="checkbox" id="post3" class="toggle">
        <label for="post3" class="post-title">
            <span class="expand-icon">+</span>
            Setting the stage: objects & notation
        </label>
        <div class="post-meta">2025/06/05</div>
        <div class="post-summary">
            <p>Let <span class="math inline">\(\mathcal{X}\times
    \mathcal{Y}\)</span> be the data space split along an input-label
    axis. The hypothesis class is a collection of functions <span class="math inline">\(f \in \mathcal{F}\)</span> <span class="math display">\[f : \mathcal{X}\times \Theta \to
    \mathcal{Y}.\]</span> For example, the hypothesis class could be a
    neural network with <span class="math inline">\(P\)</span> weights
    (and biases), then <span class="math inline">\(\Theta =
    \mathbb{R}^P\)</span> and <span class="math inline">\(f(\mathbf{\boldsymbol{x}},
    \mathbf{\boldsymbol{\theta}})\)</span> would be the function defined
    by the network....
            <a href="2025-06-05_notation.html" class="read-more">Read full post →</a>
            </p>
            
        </div>
    </div>


    <div class="generated-info">
        <p>This index was automatically generated on August 01, 2025 at 06:39 PM</p>
    </div>

</body>
</html>